{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/liamti5/UZH-Essentials-in-Text-and-Speech-Processing/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VpuIg4keplCB",
    "outputId": "a207774e-a364-419f-ac35-3e9b37756d97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.6)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (17.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (0.0.53)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2023.6.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.3.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.66.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install pandas\n",
    "# !pip install transformers\n",
    "# !pip install torch\n",
    "# !pip install sentencepiece\n",
    "# !pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-blcwdEHq7h-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "import sentencepiece\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qGi0BRggpO-O",
    "outputId": "79ee1abf-e57a-433e-8f23-0ec2f3603040"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JAaKH5g4pZ3e",
    "outputId": "cbd69207-3c01-439c-cd6f-9903e05067cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        _id  \\\n",
      "0  5a5e48e1669270001a255a05   \n",
      "1  5a5e4c87669270001a255a9e   \n",
      "2  5a5e50f3be6796001a9d7316   \n",
      "3  5a5e5127be6796001a9d7324   \n",
      "4  5a5e5161be6796001a9d7337   \n",
      "\n",
      "                                              review  \\\n",
      "0                              HSG too good for this   \n",
      "1                             Winkelmann = Ehrenmann   \n",
      "2  PROs: This module represents for the student t...   \n",
      "3  Great Prof.! Best one so far. Easy to get good...   \n",
      "4  The AC part is great but OC is trying to pack ...   \n",
      "\n",
      "                                        translations  score university  \\\n",
      "0                                   HSG zu gut dafür      1        UZH   \n",
      "1                             Winkelmann = Ehrenmann      5        UZH   \n",
      "2                                                NaN      3        UZH   \n",
      "3  Große Prof.! Beste bis jetzt. Einfach gute Not...      5        UZH   \n",
      "4  Der AC-Teil ist toll, aber OC versucht, zu vie...      2        UZH   \n",
      "\n",
      "     course  upvotes  downvotes           date  \\\n",
      "0  50044544      4.0       41.0  1548419537136   \n",
      "1  50047387      1.0        0.0  1608566977197   \n",
      "2  50772388      3.0        0.0  1578223557075   \n",
      "3  50772226      0.0        1.0  1632840742122   \n",
      "4  50740660      0.0        1.0  1626375246178   \n",
      "\n",
      "                                          courseName  \\\n",
      "0                            Corporate Finance (L+E)   \n",
      "1  Einführung in die empirische Wirtschaftsforsch...   \n",
      "2    CHE 212 Practical course in Synthetic Chemistry   \n",
      "3                        CHE 203 Organic Chemistry I   \n",
      "4          CHE 102 Fundamentals of Chemistry, Part 2   \n",
      "\n",
      "                                     courseNameShort  \n",
      "0                                  Corporate Finance  \n",
      "1  Einführung in die empirische Wirtschaftsforschung  \n",
      "2            Practical course in Synthetic Chemistry  \n",
      "3                                Organic Chemistry I  \n",
      "4                  Fundamentals of Chemistry, Part 2  \n",
      "(6642, 10)\n"
     ]
    }
   ],
   "source": [
    "with open('../data/reviews_en_translated.csv', 'r') as f:\n",
    "  df_en_tr = pd.read_csv(f)\n",
    "\n",
    "with open('../data/reviews_de.csv', 'r') as f:\n",
    "  df_de = pd.read_csv(f)\n",
    "\n",
    "df_en_tr = df_en_tr.drop(columns=[\"translation\"])\n",
    "print(df_en_tr.head())\n",
    "\n",
    "print(df_de.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPGJ2Vie8Lsx",
    "outputId": "54f35435-c71f-4642-9fc1-21bd4236dace"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        _id  score university    course  upvotes  downvotes  \\\n",
      "0  5a5e48e1669270001a255a05      1        UZH  50044544      4.0       41.0   \n",
      "1  5a5e4c87669270001a255a9e      5        UZH  50047387      1.0        0.0   \n",
      "2  5a5e50f3be6796001a9d7316      3        UZH  50772388      3.0        0.0   \n",
      "3  5a5e5127be6796001a9d7324      5        UZH  50772226      0.0        1.0   \n",
      "4  5a5e5161be6796001a9d7337      2        UZH  50740660      0.0        1.0   \n",
      "\n",
      "            date                                         courseName  \\\n",
      "0  1548419537136                            Corporate Finance (L+E)   \n",
      "1  1608566977197  Einführung in die empirische Wirtschaftsforsch...   \n",
      "2  1578223557075    CHE 212 Practical course in Synthetic Chemistry   \n",
      "3  1632840742122                        CHE 203 Organic Chemistry I   \n",
      "4  1626375246178          CHE 102 Fundamentals of Chemistry, Part 2   \n",
      "\n",
      "                                     courseNameShort  \n",
      "0                                  Corporate Finance  \n",
      "1  Einführung in die empirische Wirtschaftsforschung  \n",
      "2            Practical course in Synthetic Chemistry  \n",
      "3                                Organic Chemistry I  \n",
      "4                  Fundamentals of Chemistry, Part 2  \n"
     ]
    }
   ],
   "source": [
    "df_en_tr = df_en_tr.drop(columns=[\"review\"])\n",
    "df_en_tr = df_en_tr.rename(columns={\"translations\": \"review\"})\n",
    "print(df_en_tr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "CH9Cj-8F-Ymp",
    "outputId": "a0040285-2b17-4bc6-dadf-83322fcd5257"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "      <th>university</th>\n",
       "      <th>course</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>downvotes</th>\n",
       "      <th>date</th>\n",
       "      <th>courseName</th>\n",
       "      <th>courseNameShort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a5b6dfbaf6c59001a536aeb</td>\n",
       "      <td>interessantes aber sehr aufwändiges Fach. Die ...</td>\n",
       "      <td>3</td>\n",
       "      <td>UZH</td>\n",
       "      <td>50314925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1562135719091</td>\n",
       "      <td>Asset Pricing (V+Ü)</td>\n",
       "      <td>Asset Pricing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a5b70abaf6c59001a536b07</td>\n",
       "      <td>Warum wird Moodle Verwendet &amp; nicht OLAT? Anso...</td>\n",
       "      <td>4</td>\n",
       "      <td>UZH</td>\n",
       "      <td>50038004</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1538035078776</td>\n",
       "      <td>Mathematik I (V+Ü) (Mathematics I)</td>\n",
       "      <td>Mathematik I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a5b729faf6c59001a536b13</td>\n",
       "      <td>langwiilig, Management teil nutzlos, nur uswän...</td>\n",
       "      <td>2</td>\n",
       "      <td>UZH</td>\n",
       "      <td>50038000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1642090754318</td>\n",
       "      <td>Betriebswirtschaftslehre I (V + Ü) (Business A...</td>\n",
       "      <td>Betriebswirtschaftslehre I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5a5b7ae5af6c59001a536b80</td>\n",
       "      <td>In diesem Fach zeichnet man Flowcharts und Pro...</td>\n",
       "      <td>3</td>\n",
       "      <td>UZH</td>\n",
       "      <td>50330434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1515945190594</td>\n",
       "      <td>Wirtschaftsinformatik (V+Ü) (Business Informat...</td>\n",
       "      <td>Wirtschaftsinformatik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5a5b7d07af6c59001a536b87</td>\n",
       "      <td>weiss nöd warum so viel klaget. de dozent isch...</td>\n",
       "      <td>5</td>\n",
       "      <td>UZH</td>\n",
       "      <td>50030887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1655832259676</td>\n",
       "      <td>Statistik (V+Ü) (Statistics)</td>\n",
       "      <td>Statistik</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  5a5b6dfbaf6c59001a536aeb   \n",
       "1  5a5b70abaf6c59001a536b07   \n",
       "2  5a5b729faf6c59001a536b13   \n",
       "3  5a5b7ae5af6c59001a536b80   \n",
       "4  5a5b7d07af6c59001a536b87   \n",
       "\n",
       "                                              review  score university  \\\n",
       "0  interessantes aber sehr aufwändiges Fach. Die ...      3        UZH   \n",
       "1  Warum wird Moodle Verwendet & nicht OLAT? Anso...      4        UZH   \n",
       "2  langwiilig, Management teil nutzlos, nur uswän...      2        UZH   \n",
       "3  In diesem Fach zeichnet man Flowcharts und Pro...      3        UZH   \n",
       "4  weiss nöd warum so viel klaget. de dozent isch...      5        UZH   \n",
       "\n",
       "     course  upvotes  downvotes           date  \\\n",
       "0  50314925      0.0        1.0  1562135719091   \n",
       "1  50038004      4.0        8.0  1538035078776   \n",
       "2  50038000      0.0        1.0  1642090754318   \n",
       "3  50330434      0.0        0.0  1515945190594   \n",
       "4  50030887      1.0        0.0  1655832259676   \n",
       "\n",
       "                                          courseName  \\\n",
       "0                                Asset Pricing (V+Ü)   \n",
       "1                 Mathematik I (V+Ü) (Mathematics I)   \n",
       "2  Betriebswirtschaftslehre I (V + Ü) (Business A...   \n",
       "3  Wirtschaftsinformatik (V+Ü) (Business Informat...   \n",
       "4                       Statistik (V+Ü) (Statistics)   \n",
       "\n",
       "              courseNameShort  \n",
       "0               Asset Pricing  \n",
       "1                Mathematik I  \n",
       "2  Betriebswirtschaftslehre I  \n",
       "3       Wirtschaftsinformatik  \n",
       "4                   Statistik  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main = pd.concat([df_de, df_en_tr])\n",
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L0fAe3Py_YN8",
    "outputId": "11e4c8ac-eadf-46cd-9d96-7e356e74b2d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9725, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main['review'].replace('', np.nan, inplace=True)\n",
    "df_main.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5xyVtoA_aid"
   },
   "outputs": [],
   "source": [
    "# df_main.to_csv('/content/drive/My Drive/Colab/Uni/HS23/EITASP/main.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t9DTxcZZABG5",
    "outputId": "3c2c52bd-dcf1-42b4-cb7e-6c5d24b8b6f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9725, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_only_relevant = df_main[[\"review\", \"score\", \"university\", \"course\", \"upvotes\", \"downvotes\", \"date\"]]\n",
    "df_only_relevant.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5CpCm6goP5fh",
    "outputId": "104781b2-d6fc-4128-8635-63c7526da094"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9725, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_only_releveant = df_only_relevant.dropna(subset='review')\n",
    "df_only_relevant.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3GNsEtXbHHoO",
    "outputId": "6fa8370d-59b5-4568-c7dc-46af71f675a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  score university  \\\n",
      "0  interessantes aber sehr aufwändiges Fach. Die ...      3        UZH   \n",
      "1  Warum wird Moodle Verwendet & nicht OLAT? Anso...      4        UZH   \n",
      "2  langwiilig, Management teil nutzlos, nur uswän...      2        UZH   \n",
      "3  In diesem Fach zeichnet man Flowcharts und Pro...      3        UZH   \n",
      "4  weiss nöd warum so viel klaget. de dozent isch...      5        UZH   \n",
      "\n",
      "     course  upvotes  downvotes           date  total_votes  useful  \n",
      "0  50314925      0.0        1.0  1562135719091         -1.0       0  \n",
      "1  50038004      4.0        8.0  1538035078776         -4.0       0  \n",
      "2  50038000      0.0        1.0  1642090754318         -1.0       0  \n",
      "3  50330434      0.0        0.0  1515945190594          0.0       0  \n",
      "4  50030887      1.0        0.0  1655832259676          1.0       1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5932/2098858129.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_only_relevant['total_votes'] = df_only_relevant['upvotes'] - df_only_relevant['downvotes']\n",
      "/tmp/ipykernel_5932/2098858129.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_only_relevant['useful'] = (df_only_relevant['upvotes'] - df_only_relevant['downvotes'] > 0).astype(int)\n"
     ]
    }
   ],
   "source": [
    "df_only_relevant['total_votes'] = df_only_relevant['upvotes'] - df_only_relevant['downvotes']\n",
    "df_only_relevant['useful'] = (df_only_relevant['upvotes'] - df_only_relevant['downvotes'] > 0).astype(int)\n",
    "print(df_only_relevant.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using stuff from lecture instead of just HuggingFace models (even though some of them are also on HuggingFace ^^)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)d7125/.gitattributes: 100%|██████████| 690/690 [00:00<00:00, 2.48MB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 465kB/s]\n",
      "Downloading (…)90f41d7125/README.md: 100%|██████████| 4.01k/4.01k [00:00<00:00, 14.5MB/s]\n",
      "Downloading (…)f41d7125/config.json: 100%|██████████| 629/629 [00:00<00:00, 2.43MB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 122/122 [00:00<00:00, 497kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 69.6M/69.6M [00:06<00:00, 10.9MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 164kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 422kB/s]\n",
      "Downloading (…)d7125/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 2.53MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 314/314 [00:00<00:00, 1.51MB/s]\n",
      "Downloading (…)90f41d7125/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 869kB/s]\n",
      "Downloading (…)41d7125/modules.json: 100%|██████████| 229/229 [00:00<00:00, 801kB/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.bert.modeling_bert because of the following error (look up to see its traceback):\ncannot import name 'gather_traceback' from 'torch._C._profiler' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/.venv/lib/python3.10/site-packages/transformers/utils/import_utils.py:1184\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1184\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m module_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m   1185\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/.venv/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:26\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcheckpoint\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m nn\n",
      "File \u001b[0;32m~/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:18\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mweakref\u001b[39;00m \u001b[39mimport\u001b[39;00m ReferenceType\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlogging_tensor\u001b[39;00m \u001b[39mimport\u001b[39;00m LoggingTensorMode, capture_logs\n\u001b[1;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplatform\u001b[39;00m\n",
      "File \u001b[0;32m~/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/.venv/lib/python3.10/site-packages/torch/testing/_internal/logging_tensor.py:10\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfunctools\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_profiler\u001b[39;00m \u001b[39mimport\u001b[39;00m gather_traceback, symbolize_tracebacks\n\u001b[1;32m     13\u001b[0m _dtype_abbrs \u001b[39m=\u001b[39m {\n\u001b[1;32m     14\u001b[0m     torch\u001b[39m.\u001b[39mbfloat16: \u001b[39m\"\u001b[39m\u001b[39mbf16\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     torch\u001b[39m.\u001b[39mfloat64: \u001b[39m\"\u001b[39m\u001b[39mf64\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     torch\u001b[39m.\u001b[39muint8: \u001b[39m\"\u001b[39m\u001b[39mu8\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m }\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'gather_traceback' from 'torch._C._profiler' (unknown location)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/liamt/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/code/usefulnessPredictor.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/liamt/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/code/usefulnessPredictor.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m SentenceTransformer(\u001b[39m'\u001b[39;49m\u001b[39mparaphrase-MiniLM-L3-v2\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/liamt/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/code/usefulnessPredictor.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#Our sentences we like to encode\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/liamt/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/code/usefulnessPredictor.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m sentences \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mThis framework generates embeddings for each input sentence\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/liamt/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/code/usefulnessPredictor.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mSentences are passed as a list of string.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/liamt/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/code/usefulnessPredictor.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mThe quick brown fox jumps over the lazy dog.\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/.venv/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:95\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001b[0m\n\u001b[1;32m     87\u001b[0m         snapshot_download(model_name_or_path,\n\u001b[1;32m     88\u001b[0m                             cache_dir\u001b[39m=\u001b[39mcache_folder,\n\u001b[1;32m     89\u001b[0m                             library_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msentence-transformers\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     90\u001b[0m                             library_version\u001b[39m=\u001b[39m__version__,\n\u001b[1;32m     91\u001b[0m                             ignore_files\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mflax_model.msgpack\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrust_model.ot\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtf_model.h5\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     92\u001b[0m                             use_auth_token\u001b[39m=\u001b[39muse_auth_token)\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(model_path, \u001b[39m'\u001b[39m\u001b[39mmodules.json\u001b[39m\u001b[39m'\u001b[39m)):    \u001b[39m#Load as SentenceTransformer model\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     modules \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_sbert_model(model_path)\n\u001b[1;32m     96\u001b[0m \u001b[39melse\u001b[39;00m:   \u001b[39m#Load with AutoModel\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     modules \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_auto_model(model_path)\n",
      "File \u001b[0;32m~/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/.venv/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:840\u001b[0m, in \u001b[0;36mSentenceTransformer._load_sbert_model\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[39mfor\u001b[39;00m module_config \u001b[39min\u001b[39;00m modules_config:\n\u001b[1;32m    839\u001b[0m     module_class \u001b[39m=\u001b[39m import_from_string(module_config[\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 840\u001b[0m     module \u001b[39m=\u001b[39m module_class\u001b[39m.\u001b[39;49mload(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(model_path, module_config[\u001b[39m'\u001b[39;49m\u001b[39mpath\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n\u001b[1;32m    841\u001b[0m     modules[module_config[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m=\u001b[39m module\n\u001b[1;32m    843\u001b[0m \u001b[39mreturn\u001b[39;00m modules\n",
      "File \u001b[0;32m~/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/.venv/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:137\u001b[0m, in \u001b[0;36mTransformer.load\u001b[0;34m(input_path)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(sbert_config_path) \u001b[39mas\u001b[39;00m fIn:\n\u001b[1;32m    136\u001b[0m     config \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(fIn)\n\u001b[0;32m--> 137\u001b[0m \u001b[39mreturn\u001b[39;00m Transformer(model_name_or_path\u001b[39m=\u001b[39;49minput_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig)\n",
      "File \u001b[0;32m~/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/.venv/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:29\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[0;34m(self, model_name_or_path, max_seq_length, model_args, cache_dir, tokenizer_args, do_lower_case, tokenizer_name_or_path)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_lower_case \u001b[39m=\u001b[39m do_lower_case\n\u001b[1;32m     28\u001b[0m config \u001b[39m=\u001b[39m AutoConfig\u001b[39m.\u001b[39mfrom_pretrained(model_name_or_path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_args, cache_dir\u001b[39m=\u001b[39mcache_dir)\n\u001b[0;32m---> 29\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_model(model_name_or_path, config, cache_dir)\n\u001b[1;32m     31\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(tokenizer_name_or_path \u001b[39mif\u001b[39;00m tokenizer_name_or_path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m model_name_or_path, cache_dir\u001b[39m=\u001b[39mcache_dir, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtokenizer_args)\n\u001b[1;32m     33\u001b[0m \u001b[39m#No max_seq_length set. Try to infer from model\u001b[39;00m\n",
      "File \u001b[0;32m~/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/.venv/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:49\u001b[0m, in \u001b[0;36mTransformer._load_model\u001b[0;34m(self, model_name_or_path, config, cache_dir)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_t5_model(model_name_or_path, config, cache_dir)\n\u001b[1;32m     48\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_model \u001b[39m=\u001b[39m AutoModel\u001b[39m.\u001b[39;49mfrom_pretrained(model_name_or_path, config\u001b[39m=\u001b[39;49mconfig, cache_dir\u001b[39m=\u001b[39;49mcache_dir)\n",
      "File \u001b[0;32m~/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:562\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    559\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39mmodel_args, config\u001b[39m=\u001b[39mconfig, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    560\u001b[0m     )\n\u001b[1;32m    561\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m--> 562\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_model_mapping)\n\u001b[1;32m    563\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    564\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39mmodel_args, config\u001b[39m=\u001b[39mconfig, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    565\u001b[0m     )\n\u001b[1;32m    566\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m )\n",
      "File \u001b[0;32m~/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:392\u001b[0m, in \u001b[0;36m_get_model_class\u001b[0;34m(config, model_mapping)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_model_class\u001b[39m(config, model_mapping):\n\u001b[0;32m--> 392\u001b[0m     supported_models \u001b[39m=\u001b[39m model_mapping[\u001b[39mtype\u001b[39;49m(config)]\n\u001b[1;32m    393\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(supported_models, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    394\u001b[0m         \u001b[39mreturn\u001b[39;00m supported_models\n",
      "File \u001b[0;32m~/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:737\u001b[0m, in \u001b[0;36m_LazyAutoMapping.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[39mif\u001b[39;00m model_type \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_mapping:\n\u001b[1;32m    736\u001b[0m     model_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_mapping[model_type]\n\u001b[0;32m--> 737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_attr_from_module(model_type, model_name)\n\u001b[1;32m    739\u001b[0m \u001b[39m# Maybe there was several model types associated with this config.\u001b[39;00m\n\u001b[1;32m    740\u001b[0m model_types \u001b[39m=\u001b[39m [k \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config_mapping\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m v \u001b[39m==\u001b[39m key\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m]\n",
      "File \u001b[0;32m~/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:751\u001b[0m, in \u001b[0;36m_LazyAutoMapping._load_attr_from_module\u001b[0;34m(self, model_type, attr)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[39mif\u001b[39;00m module_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_modules:\n\u001b[1;32m    750\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_modules[module_name] \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtransformers.models\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 751\u001b[0m \u001b[39mreturn\u001b[39;00m getattribute_from_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_modules[module_name], attr)\n",
      "File \u001b[0;32m~/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:695\u001b[0m, in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(attr, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    694\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(getattribute_from_module(module, a) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m attr)\n\u001b[0;32m--> 695\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39;49m(module, attr):\n\u001b[1;32m    696\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(module, attr)\n\u001b[1;32m    697\u001b[0m \u001b[39m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39m# object at the top level.\u001b[39;00m\n",
      "File \u001b[0;32m~/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/.venv/lib/python3.10/site-packages/transformers/utils/import_utils.py:1174\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(name)\n\u001b[1;32m   1173\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m-> 1174\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_class_to_module[name])\n\u001b[1;32m   1175\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1176\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Uni/Master/HS23/EITASP/Essentials-in-Text-and-Speech-Processing/.venv/lib/python3.10/site-packages/transformers/utils/import_utils.py:1186\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m module_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m   1185\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1186\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1187\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to import \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m because of the following error (look up to see its\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1188\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m traceback):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1189\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.bert.modeling_bert because of the following error (look up to see its traceback):\ncannot import name 'gather_traceback' from 'torch._C._profiler' (unknown location)"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('paraphrase-MiniLM-L3-v2')\n",
    "\n",
    "#Our sentences we like to encode\n",
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "    'Sentences are passed as a list of string.',\n",
    "    'The quick brown fox jumps over the lazy dog.']\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Print the embeddings\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingFace BERT based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YgZh3EGsQL6z"
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-german-cased\")\n",
    "# model = AutoModel.from_pretrained(\"bert-base-german-cased\")\n",
    "# df_only_relevant['tokens'] = df_only_relevant['review'].astype(str).apply(tokenizer)\n",
    "# df_only_relevant\n",
    "# df_only_relevant.to_csv('/content/drive/My Drive/Colab/Uni/HS23/EITASP/tokenized.csv', index=False)\n",
    "\n",
    "# df = df_only_relevant\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# import numpy as np\n",
    "\n",
    "# # Pad or truncate the tokenized sequences to a fixed length\n",
    "# max_length = 512  # You can adjust this based on the data\n",
    "# X_train_padded = np.array([x[:max_length] + [0]*(max_length - len(x)) for x in X_train])\n",
    "# X_test_padded = np.array([x[:max_length] + [0]*(max_length - len(x)) for x in X_test])\n",
    "\n",
    "# # Initialize and train the Logistic Regression model\n",
    "# log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "# log_reg.fit(X_train_padded, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = log_reg.predict(X_test_padded)\n",
    "\n",
    "# # Evaluate the model\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# accuracy, classification_rep\n",
    "\n",
    "# from transformers import BertForSequenceClassification\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# import torch.optim as optim\n",
    "# import torch\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import pandas as pd\n",
    "\n",
    "# # Extract 'input_ids' from the 'BatchEncoding' objects and labels\n",
    "# X = df['tokens'].apply(lambda x: x['input_ids'])\n",
    "# y = df['useful']\n",
    "\n",
    "# # Split the data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize the model\n",
    "# model = BertForSequenceClassification.from_pretrained('google/bert_uncased_L-4_H-256_A-4', num_labels=2)\n",
    "\n",
    "# # Pad or truncate the tokenized sequences to a fixed length\n",
    "# max_length = 512  # You can adjust this based on the data\n",
    "# X_train_padded = [x[:max_length] + [0]*(max_length - len(x)) for x in X_train]\n",
    "# X_test_padded = [x[:max_length] + [0]*(max_length - len(x)) for x in X_test]\n",
    "\n",
    "# # Create DataLoader for training\n",
    "# train_dataset = TensorDataset(torch.tensor(X_train_padded, dtype=torch.long), torch.tensor(list(y_train), dtype=torch.long))\n",
    "# train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# # Create DataLoader for testing\n",
    "# test_dataset = TensorDataset(torch.tensor(X_test_padded, dtype=torch.long), torch.tensor(list(y_test), dtype=torch.long))\n",
    "# test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "\n",
    "# # Define optimizer and loss function\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
    "# loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# # Training loop\n",
    "# for epoch in range(1):  # Number of epochs\n",
    "#     model.train()\n",
    "#     for i, batch in enumerate(train_loader):\n",
    "#         input_ids, labels = batch\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(input_ids)[0]\n",
    "#         loss = loss_fn(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         if i % 100 == 0:\n",
    "#             print(f\"Epoch: {epoch}, Iteration: {i}, Loss: {loss.item()}\")\n",
    "\n",
    "# # Evaluation\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for input_ids, labels in test_loader:\n",
    "#         outputs = model(input_ids)[0]\n",
    "#         _, predicted = torch.max(outputs, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Test Accuracy: {100 * correct / total}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
